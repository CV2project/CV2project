{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial; font-weight:bold;font-size:2.5em;color:#00b3e5;\"> Milestone 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial; font-weight:bold;font-size:2em;color:#00b3e5;\"> Step 1: Import the data \\\n",
    "    Step 2: Map training and testing images to its classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for loading the training data\n",
    "validation_split = 0.3\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = tf.keras.utils.image_dataset_from_directory(\n",
    "  directory='./Car Images/Train Images',\n",
    "  label_mode='categorical',\n",
    "  validation_split=validation_split,\n",
    "  subset=\"training\",\n",
    "  shuffle=False,\n",
    "  seed=123,\n",
    "  batch_size=batch_size)\n",
    "\n",
    "validation_data = tf.keras.utils.image_dataset_from_directory(\n",
    "  directory='./Car Images/Train Images',\n",
    "  label_mode='categorical',\n",
    "  validation_split=validation_split,\n",
    "  subset=\"validation\",\n",
    "  shuffle=False,\n",
    "  seed=123,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(training_data))\n",
    "print(type(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of batches (of size 32) in the training data:', len(training_data))\n",
    "print('Shape and type of each batch in the training data:', training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Number of classes in training dataset:',np.size(training_data.class_names))\n",
    "training_data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of batches (of size 32) in the validation data:', len(validation_data))\n",
    "print('Shape and type of each batch in the validation data:', validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Number of classes in training dataset:',np.size(validation_data.class_names))\n",
    "validation_data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_labels = training_data.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial; font-weight:bold;font-size:2em;color:#00b3e5;\"> Step 3: Map training and testing images to its annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_annotations = pd.read_csv('./Annotations/Train Annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_annotations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file names corresponding to the training data in that particular order\n",
    "file_names_list = []\n",
    "\n",
    "for file_name in training_data.file_paths:\n",
    "    file_names_list.append(file_name[-9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the file names for the first 32 images (corresponds to the first batch) for checking if we assigned the class names correctly \n",
    "file_names_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the annotations data for the first 32 images\n",
    "training_annotations[training_annotations['Image Name']==file_names_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the class names for the first 32 images in the annotations data\n",
    "class_labels[training_annotations['Image class'][training_annotations['Image Name']==file_names_list[5]].values[0]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the class names for the images in the first batch in the training data\n",
    "for element in training_data.as_numpy_iterator():\n",
    "    #print(len(element[1][0]))\n",
    "    #print(np.nonzero(element[1][0])[0][0])\n",
    "    print(class_labels[np.nonzero(element[1][0])[0][0]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial; font-weight:bold;font-size:2em;color:#00b3e5;\"> Step 4: Display images with bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 32 images from the first batch\n",
    "plt.figure(figsize=(45, 45),dpi= 100)\n",
    "for images, labels in training_data.take(1):\n",
    "    for i in range(31):\n",
    "        ax = plt.subplot(16, 2, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_labels[np.nonzero(labels[i])[0][0]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
